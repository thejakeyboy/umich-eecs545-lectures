{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import imp\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops\n",
    "\n",
    "def trim(im, percent=36):\n",
    "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        x = im.crop(bbox)\n",
    "        return x.resize(((x.size[0]*percent)/100, (x.size[1]*percent)/100), Image.ANTIALIAS)\n",
    "\n",
    "def resize(filename, percent=36):\n",
    "    trim(Image.open(filename + \".png\"), percent).save(filename + \"_r\" + str(percent) + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EECS 545:  Machine Learning\n",
    "## Lecture 23:  Neural Networks (Part 2)\n",
    "* Instructor:  **Junhyuk Oh**\n",
    "* Date:  April 11, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - **Recurrent Neural Networks** \n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - Natural Language Processing\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline: Recurrent Neural Networks\n",
    "- Introduction\n",
    "- Standard RNN\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Long Short-Term Memory (LSTM)\n",
    "- Example: Character-level language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent Neural Networks (RNN)\n",
    "- A special kind of neural network designed for modeling sequential data\n",
    "  - Can take arbitrary number of inputs through time\n",
    "  - Can produce arbitrary number of outputs through time\n",
    "- Examples of sequential problems\n",
    "  - Next word prediction\n",
    "  - Machine translation\n",
    "  - Speech recognition\n",
    "  - Image caption generaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline: Recurrent Neural Networks\n",
    "- Introduction\n",
    "- **Standard RNN**\n",
    "  - **Forward Propagation**\n",
    "  - Backward Propagation\n",
    "- Long Short-Term Memory (LSTM)\n",
    "- Example: Character-level language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standard RNN\n",
    "$$ \\textbf{h}_t = f(\\textbf{W}\\textbf{x}_t + \\textbf{U}\\textbf{h}_{t-1}+\\textbf{b}) $$\n",
    "$$ \\hat{\\textbf{y}}_t = \\textbf{V}\\textbf{h}_t $$\n",
    "$$ \\mathcal{L} = \\sum_{t=1}^{T} \\mathcal{L}_t \\left( \\textbf{y}_t, \\hat{\\textbf{y}}_t \\right) $$\n",
    "- $\\textbf{W}$: input weight, $\\textbf{U}$: recurrent weight, $\\textbf{V}$: output weight, $\\textbf{b}$: bias, $f$: non-linear activation (e.g., ReLU)\n",
    "- Weights are shared across time: the number of parameters does not depend on the length of input/output sequence\n",
    "<img src=\"images/simple_rnn.png\" width=400px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forward Propagation\n",
    "<img src=\"images/simple_rnn_fprop.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline: Recurrent Neural Networks\n",
    "- Introduction\n",
    "- Standard RNN\n",
    "  - Forward Propagation\n",
    "  - **Backward Propagation**\n",
    "- Long Short-Term Memory (LSTM)\n",
    "- Example: Character-level language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation Through Time (BPTT)\n",
    "- Gradient w.r.t. hidden units (assuming that $\\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_{t+1}}$ is given)\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial \\textbf{h}_t} = \\sum_{\\tau=t}^{T}\\frac{\\partial\\mathcal{L}_{\\tau}}{\\partial \\textbf{h}_t} \\mbox { } (\\because \\frac{\\partial\\mathcal{L}_k}{\\partial \\textbf{h}_t}=0 \\mbox { if } k < t)$$ \n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial \\textbf{h}_t} = \\frac{\\partial \\mathcal{L}_t}{\\partial \\textbf{h}_t} + \\frac{\\partial \\textbf{h}_{t+1}}{\\partial \\textbf{h}_{t}} \\frac{\\partial \\sum_{\\tau=t+1}^{T}\\mathcal{L}_{\\tau}}{\\partial \\textbf{h}_{t+1}}  \\\\\n",
    "= \\underbrace{\\frac{\\partial \\mathcal{L}_t}{\\partial \\hat{\\textbf{y}}_t}}_{\\mbox{easy}}\\underbrace{\\frac{{\\partial \\hat{\\textbf{y}}_t}}{\\partial \\textbf{h}_t}}_{\\mbox{easy}} + \\underbrace{\\frac{\\partial \\textbf{h}_{t+1}}{\\partial \\textbf{h}_{t}}}_{\\mbox{easy}} \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_{t+1}}}_{\\mbox{given}} $$\n",
    "<img src=\"images/simple_rnn.png\", width=300px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation Through Time (BPTT)\n",
    "- Assume that a loss function defined as:\n",
    "$$ \\mathcal{L} = \\sum_{t=1}^{T} \\mathcal{L}_t \\left( \\textbf{y}_t, \\hat{\\textbf{y}}_t \\right) $$\n",
    "- Gradient w.r.t. input units (given $\\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_{t}}$)\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial \\textbf{x}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_t}\\frac{\\partial \\textbf{h}_t}{\\partial \\textbf{x}_t} $$\n",
    "<img src=\"images/simple_rnn.png\", width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back2.png\" width=700px align=\"middle\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back3.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back4.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back5.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back6.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back7.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation Through Time (BPTT)\n",
    "- Gradient w.r.t. weights\n",
    "  - Note: the weights are shared through time\n",
    "  - Recall: we should accumulate gradients through time\n",
    "  \n",
    "<font color='red'>$ \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{V}} = \\sum_{t=1}^{T}\\frac{\\partial \\mathcal{L}}{\\partial \\hat{\\textbf{y}}_t}\\frac{\\partial \\hat{\\textbf{y}}_t}{\\partial \\textbf{V}} $ </font> <font color='blue'>$ \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{W}} = \\sum_{t=1}^{T}\\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_t}\\frac{\\partial \\textbf{h}_t}{\\partial \\textbf{W}} $ </font> <font color='green'>$ \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{U}} = \\sum_{t=1}^{T-1}\\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_{t+1}}\\frac{\\partial \\textbf{h}_{t+1}}{\\partial \\textbf{U}} $ </font>\n",
    "<img src=\"images/simple_rnn_back_w.png\" width=600px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation Through Time (BPTT)\n",
    "- BPTT is actually not different from backpropagation.\n",
    "- RNN is actually not much different from a standard (feedforward) neural network except that:\n",
    "  - Input/output are given through time.\n",
    "  - Weights are extensively shared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline: Recurrent Neural Networks\n",
    "- Introduction\n",
    "- Standard RNN\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- **Long Short-Term Memory (LSTM)**\n",
    "- Example: Character-level language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vanshing Gradient Problem\n",
    "- RNN can model arbitrary sequences if properly trained.\n",
    "- In practice, it is difficult to train it for long-term dependencies because of vanishing gradient.\n",
    "- Intuitively, a hidden unit does not affect other units in the long-term future due to new inputs.\n",
    "  - Gradients are diffused through time\n",
    "![](images/vanish_rnn.png)\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Alex Graves)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Long Short-Term Memory (LSTM)\n",
    "- A special type of RNN for handling **vanishing gradient** problem.\n",
    "- $i_t,o_t,f_t$: **input gate**, **output gate**, and **forget gate**\n",
    "- $c_t$: **memory cell** containing information about history of inputs\n",
    "- $h_t$: output activation\n",
    "<img src=images/lstm.png width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Alex Graves)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Long Short-Term Memory (LSTM)\n",
    "- Gating mechanism control the following:\n",
    "  - whether to ignore a new input or not\n",
    "  - whether to produce an output or not (while preserving the memory cell)\n",
    "  - whether to erase the memory cell or not\n",
    "- Gating is controlled by LSTM's weights that are also learned from data.\n",
    "![](images/vanish_lstm.png)\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Alex Graves)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline: Recurrent Neural Networks\n",
    "- Introduction\n",
    "- Simple RNN\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Long Short-Term Memory (LSTM)\n",
    "- **Example: Character-level language modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Character-level language modeling\n",
    "- A character is represented as a one-of-k vector (k: #characters).\n",
    "- Goal: build a character-level generative model\n",
    "$$ P(x_1,x_2,...,x_T) = \\prod_{t=1}^{T}P(x_{t}|x_{t-1},...,x_1) \\approx \\prod_{t=1}^{T}P(x_{t}|x_{t-1},...,x_{t-n}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Character-level language modeling\n",
    "- RNN is trained to predict the next character given previous characters\n",
    "- Loss can be formulated as a sum of cross entropy losses.\n",
    "- After training, the network can generate reasonable characters.\n",
    "$$ \\mathcal{L}(\\textbf{x}) = -\\sum_{t=1}^{T}\\log P(x_{t}|x_{t-1},...,x_{t-n}; \\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Character-level language modeling\n",
    "<img src=\"images/char_rnn.png\" width=900px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Shakespeare\n",
    "<img src=\"images/char_rnn2.png\" width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Richard Socher)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wikipedia\n",
    "<img src=\"images/char_rnn3.png\" width=900px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Richard Socher)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Latex\n",
    "<img src=\"images/char_rnn4.png\" width=900px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Richard Socher)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### C++ Code\n",
    "<img src=\"images/char_rnn5.png\" width=900px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Richard Socher)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary of RNN\n",
    "- RNN is a special type of neural network that can model time-series data\n",
    "  - Weights are shared acorss time\n",
    "  - Backpropagation through time is used.\n",
    "- LSTM is a special type of RNN that is designed for handling vanishing gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - **Computer Vision** \n",
    "  - Natural Language Processing\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Object Detection\n",
    "- CNN approaches have recently achieved state-of-the-art results on object detection task.\n",
    "- Example: Regions with CNN\n",
    "  - Use a low-level region proposal methods\n",
    "  - Use a CNN to do classification for each region\n",
    "<img src=\"images/object_detection.png\" width=1000px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Girshick et al, \"Reigion-based Convolutional Networks for Accurate Object Detection and Semantic Segmentation\", PAMI, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Object Detection\n",
    "<img src=\"images/object_detection2.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figur from Ross Girshick)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Object Segmentation\n",
    "- Can be formulated as pixel-wise classification \n",
    "- Pre-trained on a large-scale classification dataset (ImageNet)\n",
    "<img src=\"images/object_segmentation.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Long et al, \"Fully Convolutional Networks for Semantic Segmentation\", CVPR, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Object Segmentation\n",
    "<img src=\"images/object_segmentation3.png\" width=650px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Noh et al, \"Learning Deconvolution Network for Semantic Segmentation\", ICCV, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Generation\n",
    "- Goal: $\\max_{\\theta} \\mathbb{E}_{\\textbf{x}} \\left[\\log P\\left(\\textbf{x} ; \\theta \\right)\\right]$\n",
    "- Outcome: the trained model can generate random samples from the learned model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### Image Generation: DRAW Network\n",
    "- Introduce a differentiable visual attention mechanism\n",
    "- Learn to move attention window through time during image generation (without any supervision).\n",
    "<img src=\"images/draw.png\" width=600px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Gregor et al, \"DRAW: A Recurrent Neural Network For Image Generation\", ICML, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Generation: DRAW Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.youtube.com/embed/Zt-7MI9eKEo\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fd116aea590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"Zt-7MI9eKEo\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Generation: Adversarial Network \n",
    "- Model : Generator (G), Discriminator (D)\n",
    "- Generator (G) : Learns to generate realistic images\n",
    "- Discriminator (D) : Learns to classify whether a given image is sampled from data or not\n",
    "- Objective : Fool each other!\n",
    "<img src=\"images/gan.png\" width=1000px />\n",
    "<!--span style=\"color:gray; font-size:10px; float:right\">(Girshick et al, \"Reigion-based Convolutional Networks for Accurate Object Detection and Semantic Segmentation\", PAMI, 2015.)</span>!-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Generation: Adversarial Network \n",
    "<img src=\"images/gan2.png\" width=1000px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Radford et al, \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\", ICLR, 2016.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Generation: Adversarial Network \n",
    "<img src=\"images/gan3.png\" width=1000px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Radford et al, \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\", ICLR, 2016.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Video Prediction\n",
    "- Predict future frames given previous frames and actions\n",
    "<img src=\"images/video_prediction.png\" />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Oh et al, \"Action-Conditional Video Prediction using Deep Networks in Atari Games\", NIPS, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Video Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.youtube.com/embed/7FBFhG2LgNQ\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fd116aea310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"7FBFhG2LgNQ\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - **Natural Language Processing**\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequence-to-Sequence Learning Framework\n",
    "- A general RNN framework for sequence-to-sequence prediction\n",
    "$$ P \\left(y_1, y_2, ... , y_{T'} \\vert x_1, x_2, ..., x_{T} \\right)$$\n",
    "<img src=\"images/seq_to_seq.png\" />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Sutskever et al, \"Sequence to Sequence Learning with Neural Networks\", NIPS, 2014.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Seq2Seq: Application to Machine Translation\n",
    "- Achives state-of-the-art results on English-to-French dataset.\n",
    "<img src=\"images/seq_to_seq2.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Sutskever et al, \"Sequence to Sequence Learning with Neural Networks\", NIPS, 2014.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Seq2Seq: Application to Grammar Parsing\n",
    "- A parsing tree can be represented as a sequence\n",
    "- Seq2Seq framework can be applied (sentence $\\rightarrow$ parse tree)\n",
    "<img src=\"images/grammar.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Vinyals et al, \"Grammar as a Foreign Language\", NIPS, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Seq2Seq: Application to Grammar Parsing\n",
    "\n",
    "<img src=\"images/grammar2.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Vinyals et al, \"Grammar as a Foreign Language\", NIPS, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Seq2Seq: Application to Python Execution\n",
    "- Input: source code\n",
    "- Output: execution result\n",
    "<img src=\"images/python.png\" />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Zaremba et al, \"Learning to Execute\", ICLR, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Seq2Seq: Application to Python Execution\n",
    "<img src=\"images/python2.png\" />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Zaremba et al, \"Learning to Execute\", ICLR, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Caption Generation\n",
    "- Idea proposed by Vinyals et al.\n",
    "  - Use a pre-trained CNN to extract image features\n",
    "  - Condition a RNN for generating an image description.\n",
    "<img src=\"images/image_caption.png\" />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Vinyals et al, \"Show and Tell: A Neural Image Caption Generator\", CVPR, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Caption Generation\n",
    "<img src=\"images/image_caption2.png\" width=1000px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Vinyals et al, \"Show and Tell: A Neural Image Caption Generator\", CVPR, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Caption Generation\n",
    "- Another idea proposed by Xu et al.\n",
    "  - Let the model pay attention to only a part of an image when generating a word.\n",
    "<img src=\"images/image_caption3.png\" width=700px />\n",
    "<img src=\"images/image_caption4.png\" width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Xu et al, \"Show, Attend and Tell: Neural Image Caption\n",
    "Generation with Visual Attention\", ICML, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Caption Generation\n",
    "- Some examples from the work by Kiros et al.\n",
    "<img src=\"images/image_caption6.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figures from Ruslan Salakhutdinov)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - Natural Language Processing\n",
    "  - **Reinforcement Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reinforcement Learning\n",
    "- An agent observes a state $s_t$, chooses an action $a_t$, receives a reward $r_t$, and goes to the next state $s_{t+1}$.\n",
    "- The goal is to maximize the total reward until the episode terminates (episodic task).\n",
    "<img src=\"images/rl.png\" width=600px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from \"Reinforcement Learning: An Introduction\" by Richard S. Sutton and Andrew G. Barto)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Brief Summary of Q-Learning\n",
    "- $Q(s,a)$: expected total future reward for choosing action $a$ at state $s$.\n",
    "- The agent learns to estimate $Q(s,a)$ by trial-and-error.\n",
    "- Greedy policy: $\\mbox{argmax}_a Q(s,a)$\n",
    "- Problem: need to approximate $Q(s,a)$ when the state space is very large.\n",
    "<img src=\"images/rl.png\" width=600px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from \"Reinforcement Learning: An Introduction\" by Richard S. Sutton and Andrew G. Barto)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Q-Network\n",
    "- A recent breakthrough from Google DeepMind\n",
    "- Achieves human-level performances on many Atari 2600 games\n",
    "<img src=\"images/dqn.png\" width=300px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Minh et al. \"Human-level control through deep reinforcement learning\", Nature, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Q-Network\n",
    "- Key idea: Use CNN to approximate Q-values\n",
    "<img src=\"images/dqn2.png\" width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Minh et al. \"Human-level control through deep reinforcement learning\", Nature, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.youtube.com/embed/Q70ulPJW3Gk\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fd116aea3d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"Q70ulPJW3Gk\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AlphaGo\n",
    "- Another breakthrough from Google DeepMind\n",
    "- Achieves super-human performance on Go\n",
    "<img src=\"images/alphago.jpg\" width=300px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Silver et al. \"Mastering the game of Go with deep neural networks and tree search\", Nature, 2016.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Brief Summary of Monte-Carlo Tree Search (MTCS)\n",
    "- Simulate many possible futures and choose the best action\n",
    "- Problem: search space is too large!\n",
    "  - Search over only a reasonable state space (tree policy should be reasonable).\n",
    "  - Search up to a certain depth and use a default policy to get the outcome.\n",
    "<img src=\"images/alphago2.png\" width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Browne et al.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AlphaGo\n",
    "- Idea: use a deep CNN to learn a reasonable policy\n",
    "  0. Supervised Learning: Train a **policy network** to predict human expert's move.\n",
    "  0. Reinforcement Learning: Improve the policy network through self-play.\n",
    "  0. Reinforcement Learning: Train a **value network** to predict whether the agent wins at the end or not.\n",
    "  0. Use the learned networks to do MCTS more efficiently!</span>\n",
    "<img src=\"images/alphago3.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Silver et al. \"Mastering the game of Go with deep neural networks and tree search\", Nature, 2016.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AlphaGo\n",
    "- Result: AlphaGo beat Lee Sedol (the worldâ€™s top Go player).\n",
    "<!-- (Photo : Google Handout | Getty Images) !-->\n",
    "<img src=\"images/alphago5.jpg\", width=400px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary \n",
    "- Deep Learning: machine learning algorithms based on learning multiple levels of representation.\n",
    "- Neural networks can implement the idea of deep learning in a very flexible way.\n",
    "- Deep neural networks (e.g., CNN, RNN) have made remarkable advances in computer vision, natural language processing, and reinforcement learning area.\n",
    "- Open problems\n",
    "  - Unsupservised learning\n",
    "  - Learning long-term dependencies\n",
    "  - Data efficiency"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
